{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oauth keys\n",
    "consumer_key =    \"oSvfqpSUySTGosgcgRJqZnJv6\"\n",
    "consumer_secret = \"44BNZrpl4BbxFdHdlmGLcB0cqgylVL9D7jvYadWjjuENHkzVz1\"\n",
    "access_token = \"1525783737371226114-CEnQlvbAIJEZpx0BCIS2dvBtlQjd8q\"\n",
    "access_token_secret = \"JcwX3rWjY0pk1XIdyEydNSQVLzts5Q80j4LWljI22llRc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import tweepy\n",
    "import ssl\n",
    "import snscrape\n",
    "import pandas as pd\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "\n",
    "# Authentication with Twitter\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_categories = {\n",
    "    'Entertainer': ['sofyank96', 'LuqmanPodolski', 'hazemanhuzir','CeddyOrNot', 'brgsjks', 'Azfarheri', 'Matluthfi90' ],\n",
    "    'Politics': ['chairman_GLC', 'Khairykj', 'MuhyiddinYassin', 'limlipeng', 'kuasasiswa', 'NajibRazak', 'n_izzah', 'anwaribrahim', 'SyedSaddiq'],\n",
    "    'Technology': ['XavierNaxa', 'fazlihalimmedia', 'thefaizzainal','aribismail','acaiijawe' ],\n",
    "    'Celebrity': ['altimet', 'AfikryAibrahim', 'yunamusic', 'CTNurhaliza11', 'AaronDwiAziz', 'missfazura','Nor4Danish','Shaheizy_Sam' ],\n",
    "    'Entrepreneur': ['FezzaHussin', 'adibhazlami', 'afiqnazary','AmirulMu_min', 'richardker', 'IZZTAZWAR', 'khairulaming'],\n",
    "    'Fitness and others': ['najibfazail', 'fedtriyahya', 'Pandelela_R', 'ijaicool', \"DrAmalinaBakri\"]\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scrape_tweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\CODING TWITTER PROJECT\\0.0 SCRAPING.ipynb Cell 5\u001b[0m in \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CODING%20TWITTER%20PROJECT/0.0%20SCRAPING.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m username \u001b[39min\u001b[39;00m username_list:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CODING%20TWITTER%20PROJECT/0.0%20SCRAPING.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     query \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mfrom:\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m username\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m until:2021-12-31 since:2021-01-01 -filter:replies\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/CODING%20TWITTER%20PROJECT/0.0%20SCRAPING.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     test \u001b[39m=\u001b[39m scrape_tweets(query\u001b[39m=\u001b[39mquery, limit\u001b[39m=\u001b[39m limit)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CODING%20TWITTER%20PROJECT/0.0%20SCRAPING.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     tweet\u001b[39m.\u001b[39mappend(test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CODING%20TWITTER%20PROJECT/0.0%20SCRAPING.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m MainTweet \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(tweet)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scrape_tweets' is not defined"
     ]
    }
   ],
   "source": [
    "username_list = [user for category, users in user_categories.items() for user in users]\n",
    "tweet= []\n",
    "result = []\n",
    "limit = 500\n",
    "for username in username_list:\n",
    "    query = 'from:' + username+' until:2021-12-31 since:2021-01-01 -filter:replies'\n",
    "    test = scrape_tweets(query=query, limit= limit)\n",
    "    tweet.append(test)\n",
    "\n",
    "\n",
    "MainTweet = pd.concat(tweet)\n",
    "MainTweet.reset_index(drop= True, inplace = True)\n",
    "MainTweet\n",
    "df = pd.DataFrame(MainTweet,columns = [ 'Username', 'Text',\"Date Created\", \"Number of Likes\", \"Number of Retweet\", \"Number of Replies\", \"Source of Tweet\", 'User ID', 'Conversation ID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "query = 'from:@XavierNaxa since:2023-01-01 -filter:replies'\n",
    "count = 1\n",
    "\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search_tweets, q=query, count=100).items(100):\n",
    "    \n",
    "    print(count)\n",
    "    count += 1\n",
    "\n",
    "    try: \n",
    "        data = [tweet.created_at, tweet.id, tweet.text, tweet.user._json['screen_name'], tweet.user._json['name'], tweet.user._json['created_at'], tweet.entities['urls']]\n",
    "        data = tuple(data)\n",
    "        tweets.append(data)\n",
    "\n",
    "    except tweepy.TweepError as e:\n",
    "        print(e.reason)\n",
    "        continue\n",
    "\n",
    "    except StopIteration:\n",
    "        break\n",
    "\n",
    "df = pd.DataFrame(tweets, columns = ['created_at','tweet_id', 'tweet_text', 'screen_name', 'name', 'account_creation_date', 'urls'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "query = 'from:@XavierNaxa -is:retweet -filter:replies '\n",
    "count = 1\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search_tweets, q=query, count=100, until= '2023-02-02').items(100):\n",
    "    \n",
    "    print(count)\n",
    "    count += 1\n",
    "\n",
    "    try: \n",
    "        data = [tweet.created_at, tweet.id, tweet.text, tweet.in_reply_to_status_id_str, tweet.user._json['screen_name'], tweet.user._json['name'], tweet.user._json['created_at'], tweet.entities['urls'], tweet.favorite_count, tweet.retweet_count, tweet.reply_count if hasattr(tweet, 'reply_count') else 0, tweet.quote_count if hasattr(tweet, 'quote_count') else 0]\n",
    "        data = tuple(data)\n",
    "        tweets.append(data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "    except StopIteration:\n",
    "        break\n",
    "\n",
    "df = pd.DataFrame(tweets, columns=['created_at', 'tweet_id', 'tweet_text','conversation_id', 'screen_name', 'name', 'account_creation_date', 'urls', 'favorite_count', 'retweet_count', 'reply_count', 'quote_count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>name</th>\n",
       "      <th>account_creation_date</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-05 01:19:26+00:00</td>\n",
       "      <td>1643423063516512257</td>\n",
       "      <td>RT @BNonnecke: üö® üìÖ Wednesday, 4/19, 4:10pm ‚Äì J...</td>\n",
       "      <td>JessicaScott09</td>\n",
       "      <td>Jessica Scott @jessicascott09@infosec.exchange</td>\n",
       "      <td>Thu Mar 12 17:19:00 +0000 2009</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-04 16:48:30+00:00</td>\n",
       "      <td>1643294483629367296</td>\n",
       "      <td>RT @BNonnecke: üö® üìÖ Wednesday, 4/19, 4:10pm ‚Äì J...</td>\n",
       "      <td>BostonJoan</td>\n",
       "      <td>Joan Donovan, PhD</td>\n",
       "      <td>Thu Mar 11 16:39:39 +0000 2010</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-02 03:51:24+00:00</td>\n",
       "      <td>1642374145605529602</td>\n",
       "      <td>@PamelaSamuelson @BNonnecke Credit?</td>\n",
       "      <td>ApelEins</td>\n",
       "      <td>Hans Apel</td>\n",
       "      <td>Sun Jan 30 03:25:22 +0000 2011</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-02 03:05:41+00:00</td>\n",
       "      <td>1642362638788349953</td>\n",
       "      <td>@BNonnecke No, a Mexican artist probably inspi...</td>\n",
       "      <td>PamelaSamuelson</td>\n",
       "      <td>Pamela Samuelson</td>\n",
       "      <td>Sun Apr 15 00:38:14 +0000 2012</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-01 20:59:09+00:00</td>\n",
       "      <td>1642270398162038784</td>\n",
       "      <td>RT @BNonnecke: In 1964, Marshall McLuhan naile...</td>\n",
       "      <td>jimmyroybloom</td>\n",
       "      <td>James Bloom</td>\n",
       "      <td>Mon Apr 27 15:55:12 +0000 2009</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-03-30 14:14:37+00:00</td>\n",
       "      <td>1641443818422812684</td>\n",
       "      <td>@BNonnecke @vincentghoste I agree. I have lear...</td>\n",
       "      <td>dcmaxwell08</td>\n",
       "      <td>Maxwell_</td>\n",
       "      <td>Tue Jan 18 23:00:31 +0000 2022</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-03-30 04:29:55+00:00</td>\n",
       "      <td>1641296671735787522</td>\n",
       "      <td>@BNonnecke https://t.co/VApNDPEt4E</td>\n",
       "      <td>vincentghoste</td>\n",
       "      <td>VincentGhoste.eth üëª‚ù§Ô∏è</td>\n",
       "      <td>Sun Dec 06 18:46:22 +0000 2015</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-03-29 19:40:59+00:00</td>\n",
       "      <td>1641163563732733952</td>\n",
       "      <td>@BNonnecke Though thanks for flagging it. Appr...</td>\n",
       "      <td>foyerwork</td>\n",
       "      <td>Merlin by Foyer</td>\n",
       "      <td>Tue Nov 02 17:40:59 +0000 2021</td>\n",
       "      <td>[{'url': 'https://t.co/D8OPZHyTRM', 'expanded_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-03-29 19:38:06+00:00</td>\n",
       "      <td>1641162836557828103</td>\n",
       "      <td>@BNonnecke ... might sound smart and may look ...</td>\n",
       "      <td>foyerwork</td>\n",
       "      <td>Merlin by Foyer</td>\n",
       "      <td>Tue Nov 02 17:40:59 +0000 2021</td>\n",
       "      <td>[{'url': 'https://t.co/cVbMAqUy0o', 'expanded_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-03-29 19:35:02+00:00</td>\n",
       "      <td>1641162064377917441</td>\n",
       "      <td>@BNonnecke ... this we are exploring ways to m...</td>\n",
       "      <td>foyerwork</td>\n",
       "      <td>Merlin by Foyer</td>\n",
       "      <td>Tue Nov 02 17:40:59 +0000 2021</td>\n",
       "      <td>[{'url': 'https://t.co/7Tw1Aa4PUv', 'expanded_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at             tweet_id  \\\n",
       "0 2023-04-05 01:19:26+00:00  1643423063516512257   \n",
       "1 2023-04-04 16:48:30+00:00  1643294483629367296   \n",
       "2 2023-04-02 03:51:24+00:00  1642374145605529602   \n",
       "3 2023-04-02 03:05:41+00:00  1642362638788349953   \n",
       "4 2023-04-01 20:59:09+00:00  1642270398162038784   \n",
       "5 2023-03-30 14:14:37+00:00  1641443818422812684   \n",
       "6 2023-03-30 04:29:55+00:00  1641296671735787522   \n",
       "7 2023-03-29 19:40:59+00:00  1641163563732733952   \n",
       "8 2023-03-29 19:38:06+00:00  1641162836557828103   \n",
       "9 2023-03-29 19:35:02+00:00  1641162064377917441   \n",
       "\n",
       "                                          tweet_text      screen_name  \\\n",
       "0  RT @BNonnecke: üö® üìÖ Wednesday, 4/19, 4:10pm ‚Äì J...   JessicaScott09   \n",
       "1  RT @BNonnecke: üö® üìÖ Wednesday, 4/19, 4:10pm ‚Äì J...       BostonJoan   \n",
       "2                @PamelaSamuelson @BNonnecke Credit?         ApelEins   \n",
       "3  @BNonnecke No, a Mexican artist probably inspi...  PamelaSamuelson   \n",
       "4  RT @BNonnecke: In 1964, Marshall McLuhan naile...    jimmyroybloom   \n",
       "5  @BNonnecke @vincentghoste I agree. I have lear...      dcmaxwell08   \n",
       "6                 @BNonnecke https://t.co/VApNDPEt4E    vincentghoste   \n",
       "7  @BNonnecke Though thanks for flagging it. Appr...        foyerwork   \n",
       "8  @BNonnecke ... might sound smart and may look ...        foyerwork   \n",
       "9  @BNonnecke ... this we are exploring ways to m...        foyerwork   \n",
       "\n",
       "                                             name  \\\n",
       "0  Jessica Scott @jessicascott09@infosec.exchange   \n",
       "1                               Joan Donovan, PhD   \n",
       "2                                       Hans Apel   \n",
       "3                                Pamela Samuelson   \n",
       "4                                     James Bloom   \n",
       "5                                        Maxwell_   \n",
       "6                           VincentGhoste.eth üëª‚ù§Ô∏è   \n",
       "7                                 Merlin by Foyer   \n",
       "8                                 Merlin by Foyer   \n",
       "9                                 Merlin by Foyer   \n",
       "\n",
       "            account_creation_date  \\\n",
       "0  Thu Mar 12 17:19:00 +0000 2009   \n",
       "1  Thu Mar 11 16:39:39 +0000 2010   \n",
       "2  Sun Jan 30 03:25:22 +0000 2011   \n",
       "3  Sun Apr 15 00:38:14 +0000 2012   \n",
       "4  Mon Apr 27 15:55:12 +0000 2009   \n",
       "5  Tue Jan 18 23:00:31 +0000 2022   \n",
       "6  Sun Dec 06 18:46:22 +0000 2015   \n",
       "7  Tue Nov 02 17:40:59 +0000 2021   \n",
       "8  Tue Nov 02 17:40:59 +0000 2021   \n",
       "9  Tue Nov 02 17:40:59 +0000 2021   \n",
       "\n",
       "                                                urls  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2                                                 []  \n",
       "3                                                 []  \n",
       "4                                                 []  \n",
       "5                                                 []  \n",
       "6                                                 []  \n",
       "7  [{'url': 'https://t.co/D8OPZHyTRM', 'expanded_...  \n",
       "8  [{'url': 'https://t.co/cVbMAqUy0o', 'expanded_...  \n",
       "9  [{'url': 'https://t.co/7Tw1Aa4PUv', 'expanded_...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "            data.append([tweets.user.username,tweets.content,tweets.date,\n",
    "            tweets.likeCount,tweets.retweetCount, tweets.replyCount,\n",
    "            tweets.sourceLabel, tweets.id, tweets.conversationId])\n",
    "    return pd.DataFrame(data, columns=['Username', 'Text',\"Date Created\",\n",
    "     \"Number of Likes\", \"Number of Retweet\", \"Number of Replies\",\n",
    "      \"Source of Tweet\", 'User ID', 'Conversation ID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>name</th>\n",
       "      <th>account_creation_date</th>\n",
       "      <th>urls</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>quote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-06 08:42:56+00:00</td>\n",
       "      <td>1643897062424207360</td>\n",
       "      <td>Saya dapati ramai yang hadapi masalah seperti ...</td>\n",
       "      <td>None</td>\n",
       "      <td>XavierNaxa</td>\n",
       "      <td>Xavier Naxa</td>\n",
       "      <td>Tue Jul 21 15:55:47 +0000 2015</td>\n",
       "      <td>[{'url': 'https://t.co/wRUcPBKSh7', 'expanded_...</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-06 01:14:18+00:00</td>\n",
       "      <td>1643784160618889217</td>\n",
       "      <td>Selepas menggunakan kedua-dua permesejan ini, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>XavierNaxa</td>\n",
       "      <td>Xavier Naxa</td>\n",
       "      <td>Tue Jul 21 15:55:47 +0000 2015</td>\n",
       "      <td>[{'url': 'https://t.co/MAxlfi8xVi', 'expanded_...</td>\n",
       "      <td>78</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-05 20:58:16+00:00</td>\n",
       "      <td>1643719727569838086</td>\n",
       "      <td>iPhone X merupakan model pertama hadir dengan ...</td>\n",
       "      <td>None</td>\n",
       "      <td>XavierNaxa</td>\n",
       "      <td>Xavier Naxa</td>\n",
       "      <td>Tue Jul 21 15:55:47 +0000 2015</td>\n",
       "      <td>[{'url': 'https://t.co/7Wd3clYD4c', 'expanded_...</td>\n",
       "      <td>108</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-05 19:53:00+00:00</td>\n",
       "      <td>1643703300649545728</td>\n",
       "      <td>Skeuomorphism ‚û°Ô∏è Flat ‚û°Ô∏è Neumorphism</td>\n",
       "      <td>None</td>\n",
       "      <td>XavierNaxa</td>\n",
       "      <td>Xavier Naxa</td>\n",
       "      <td>Tue Jul 21 15:55:47 +0000 2015</td>\n",
       "      <td>[]</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-05 19:36:32+00:00</td>\n",
       "      <td>1643699160531734528</td>\n",
       "      <td>Terdapat khabar angin yang dikongsi oleh @MacR...</td>\n",
       "      <td>None</td>\n",
       "      <td>XavierNaxa</td>\n",
       "      <td>Xavier Naxa</td>\n",
       "      <td>Tue Jul 21 15:55:47 +0000 2015</td>\n",
       "      <td>[{'url': 'https://t.co/JeF1omLWCv', 'expanded_...</td>\n",
       "      <td>123</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2023-03-28 22:14:58+00:00</td>\n",
       "      <td>1640839925330505728</td>\n",
       "      <td>Dungeons &amp;amp; Dragons: Honor Among Thieves se...</td>\n",
       "      <td>None</td>\n",
       "      <td>XavierNaxa</td>\n",
       "      <td>Xavier Naxa</td>\n",
       "      <td>Tue Jul 21 15:55:47 +0000 2015</td>\n",
       "      <td>[{'url': 'https://t.co/fmmXEneP3K', 'expanded_...</td>\n",
       "      <td>155</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2023-03-28 21:35:23+00:00</td>\n",
       "      <td>1640829963808149505</td>\n",
       "      <td>Adakah anda setuju Apple membuang slot SIM Nan...</td>\n",
       "      <td>None</td>\n",
       "      <td>XavierNaxa</td>\n",
       "      <td>Xavier Naxa</td>\n",
       "      <td>Tue Jul 21 15:55:47 +0000 2015</td>\n",
       "      <td>[]</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2023-03-28 21:30:58+00:00</td>\n",
       "      <td>1640828852103675909</td>\n",
       "      <td>Salam sahur rakan-rakan Twitter saya. https://...</td>\n",
       "      <td>None</td>\n",
       "      <td>XavierNaxa</td>\n",
       "      <td>Xavier Naxa</td>\n",
       "      <td>Tue Jul 21 15:55:47 +0000 2015</td>\n",
       "      <td>[]</td>\n",
       "      <td>3509</td>\n",
       "      <td>1025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2023-03-28 20:59:34+00:00</td>\n",
       "      <td>1640820951507144712</td>\n",
       "      <td>Terima kasih @GSCinemas atas jemputan menonton...</td>\n",
       "      <td>None</td>\n",
       "      <td>XavierNaxa</td>\n",
       "      <td>Xavier Naxa</td>\n",
       "      <td>Tue Jul 21 15:55:47 +0000 2015</td>\n",
       "      <td>[]</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2023-03-28 20:53:47+00:00</td>\n",
       "      <td>1640819494829559812</td>\n",
       "      <td>HomePod dan HomePod mini akan dilancarkan ke S...</td>\n",
       "      <td>None</td>\n",
       "      <td>XavierNaxa</td>\n",
       "      <td>Xavier Naxa</td>\n",
       "      <td>Tue Jul 21 15:55:47 +0000 2015</td>\n",
       "      <td>[{'url': 'https://t.co/K0MHra5rpO', 'expanded_...</td>\n",
       "      <td>103</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  created_at             tweet_id  \\\n",
       "0  2023-04-06 08:42:56+00:00  1643897062424207360   \n",
       "1  2023-04-06 01:14:18+00:00  1643784160618889217   \n",
       "2  2023-04-05 20:58:16+00:00  1643719727569838086   \n",
       "3  2023-04-05 19:53:00+00:00  1643703300649545728   \n",
       "4  2023-04-05 19:36:32+00:00  1643699160531734528   \n",
       "..                       ...                  ...   \n",
       "95 2023-03-28 22:14:58+00:00  1640839925330505728   \n",
       "96 2023-03-28 21:35:23+00:00  1640829963808149505   \n",
       "97 2023-03-28 21:30:58+00:00  1640828852103675909   \n",
       "98 2023-03-28 20:59:34+00:00  1640820951507144712   \n",
       "99 2023-03-28 20:53:47+00:00  1640819494829559812   \n",
       "\n",
       "                                           tweet_text conversation_id  \\\n",
       "0   Saya dapati ramai yang hadapi masalah seperti ...            None   \n",
       "1   Selepas menggunakan kedua-dua permesejan ini, ...            None   \n",
       "2   iPhone X merupakan model pertama hadir dengan ...            None   \n",
       "3                Skeuomorphism ‚û°Ô∏è Flat ‚û°Ô∏è Neumorphism            None   \n",
       "4   Terdapat khabar angin yang dikongsi oleh @MacR...            None   \n",
       "..                                                ...             ...   \n",
       "95  Dungeons &amp; Dragons: Honor Among Thieves se...            None   \n",
       "96  Adakah anda setuju Apple membuang slot SIM Nan...            None   \n",
       "97  Salam sahur rakan-rakan Twitter saya. https://...            None   \n",
       "98  Terima kasih @GSCinemas atas jemputan menonton...            None   \n",
       "99  HomePod dan HomePod mini akan dilancarkan ke S...            None   \n",
       "\n",
       "   screen_name         name           account_creation_date  \\\n",
       "0   XavierNaxa  Xavier Naxa  Tue Jul 21 15:55:47 +0000 2015   \n",
       "1   XavierNaxa  Xavier Naxa  Tue Jul 21 15:55:47 +0000 2015   \n",
       "2   XavierNaxa  Xavier Naxa  Tue Jul 21 15:55:47 +0000 2015   \n",
       "3   XavierNaxa  Xavier Naxa  Tue Jul 21 15:55:47 +0000 2015   \n",
       "4   XavierNaxa  Xavier Naxa  Tue Jul 21 15:55:47 +0000 2015   \n",
       "..         ...          ...                             ...   \n",
       "95  XavierNaxa  Xavier Naxa  Tue Jul 21 15:55:47 +0000 2015   \n",
       "96  XavierNaxa  Xavier Naxa  Tue Jul 21 15:55:47 +0000 2015   \n",
       "97  XavierNaxa  Xavier Naxa  Tue Jul 21 15:55:47 +0000 2015   \n",
       "98  XavierNaxa  Xavier Naxa  Tue Jul 21 15:55:47 +0000 2015   \n",
       "99  XavierNaxa  Xavier Naxa  Tue Jul 21 15:55:47 +0000 2015   \n",
       "\n",
       "                                                 urls  favorite_count  \\\n",
       "0   [{'url': 'https://t.co/wRUcPBKSh7', 'expanded_...              35   \n",
       "1   [{'url': 'https://t.co/MAxlfi8xVi', 'expanded_...              78   \n",
       "2   [{'url': 'https://t.co/7Wd3clYD4c', 'expanded_...             108   \n",
       "3                                                  []              23   \n",
       "4   [{'url': 'https://t.co/JeF1omLWCv', 'expanded_...             123   \n",
       "..                                                ...             ...   \n",
       "95  [{'url': 'https://t.co/fmmXEneP3K', 'expanded_...             155   \n",
       "96                                                 []              22   \n",
       "97                                                 []            3509   \n",
       "98                                                 []              51   \n",
       "99  [{'url': 'https://t.co/K0MHra5rpO', 'expanded_...             103   \n",
       "\n",
       "    retweet_count  reply_count  quote_count  \n",
       "0              11            0            0  \n",
       "1              27            0            0  \n",
       "2              26            0            0  \n",
       "3               5            0            0  \n",
       "4              26            0            0  \n",
       "..            ...          ...          ...  \n",
       "95             35            0            0  \n",
       "96              3            0            0  \n",
       "97           1025            0            0  \n",
       "98              2            0            0  \n",
       "99             14            0            0  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error retrieving https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&simple_quoted_tweets=true&q=%28from%3ABBC%29+until%3A2023-01-12+since%3A2023-01-08+-filter%3Areplies&tweet_search_mode=live&count=100&query_source=spelling_expansion_revert_click&pc=1&spelling_corrections=1&ext=mediaStats%2ChighlightedLabel: non-200 status code\n",
      "4 requests to https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&simple_quoted_tweets=true&q=%28from%3ABBC%29+until%3A2023-01-12+since%3A2023-01-08+-filter%3Areplies&tweet_search_mode=live&count=100&query_source=spelling_expansion_revert_click&pc=1&spelling_corrections=1&ext=mediaStats%2ChighlightedLabel failed, giving up.\n"
     ]
    },
    {
     "ename": "ScraperException",
     "evalue": "4 requests to https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&simple_quoted_tweets=true&q=%28from%3ABBC%29+until%3A2023-01-12+since%3A2023-01-08+-filter%3Areplies&tweet_search_mode=live&count=100&query_source=spelling_expansion_revert_click&pc=1&spelling_corrections=1&ext=mediaStats%2ChighlightedLabel failed, giving up.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mScraperException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32md:\\CODING TWITTER PROJECT\\0.0 SCRAPING.ipynb Cell 11\u001b[0m in \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CODING%20TWITTER%20PROJECT/0.0%20SCRAPING.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m news_data \u001b[39min\u001b[39;00m news:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CODING%20TWITTER%20PROJECT/0.0%20SCRAPING.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     limit \u001b[39m=\u001b[39m \u001b[39m500\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/CODING%20TWITTER%20PROJECT/0.0%20SCRAPING.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mfor\u001b[39;00m tweet \u001b[39min\u001b[39;00m sntwitter\u001b[39m.\u001b[39mTwitterSearchScraper(news_data)\u001b[39m.\u001b[39mget_items():\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CODING%20TWITTER%20PROJECT/0.0%20SCRAPING.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CODING%20TWITTER%20PROJECT/0.0%20SCRAPING.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39m# print(vars(tweet))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CODING%20TWITTER%20PROJECT/0.0%20SCRAPING.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         \u001b[39m# break\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CODING%20TWITTER%20PROJECT/0.0%20SCRAPING.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(tweets) \u001b[39m==\u001b[39m limit:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CODING%20TWITTER%20PROJECT/0.0%20SCRAPING.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m             \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Fikri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\snscrape\\modules\\twitter.py:680\u001b[0m, in \u001b[0;36mTwitterSearchScraper.get_items\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    677\u001b[0m \t\u001b[39mdel\u001b[39;00m params[\u001b[39m'\u001b[39m\u001b[39mtweet_search_mode\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    678\u001b[0m \t\u001b[39mdel\u001b[39;00m paginationParams[\u001b[39m'\u001b[39m\u001b[39mtweet_search_mode\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m--> 680\u001b[0m \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_api_data(\u001b[39m'\u001b[39m\u001b[39mhttps://api.twitter.com/2/search/adaptive.json\u001b[39m\u001b[39m'\u001b[39m, params, paginationParams, cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cursor):\n\u001b[0;32m    681\u001b[0m \t\u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_instructions_to_tweets(obj)\n",
      "File \u001b[1;32mc:\\Users\\Fikri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\snscrape\\modules\\twitter.py:369\u001b[0m, in \u001b[0;36m_TwitterAPIScraper._iter_api_data\u001b[1;34m(self, endpoint, params, paginationParams, cursor, direction)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    368\u001b[0m \t_logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRetrieving scroll page \u001b[39m\u001b[39m{\u001b[39;00mcursor\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 369\u001b[0m \tobj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_api_data(endpoint, reqParams)\n\u001b[0;32m    370\u001b[0m \t\u001b[39myield\u001b[39;00m obj\n\u001b[0;32m    372\u001b[0m \t\u001b[39m# No data format test, just a hard and loud crash if anything's wrong :-)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Fikri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\snscrape\\modules\\twitter.py:339\u001b[0m, in \u001b[0;36m_TwitterAPIScraper._get_api_data\u001b[1;34m(self, endpoint, params)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_api_data\u001b[39m(\u001b[39mself\u001b[39m, endpoint, params):\n\u001b[0;32m    338\u001b[0m \t\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_guest_token()\n\u001b[1;32m--> 339\u001b[0m \tr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get(endpoint, params \u001b[39m=\u001b[39;49m params, headers \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apiHeaders, responseOkCallback \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_api_response)\n\u001b[0;32m    340\u001b[0m \t\u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    341\u001b[0m \t\tobj \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[1;32mc:\\Users\\Fikri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\snscrape\\base.py:216\u001b[0m, in \u001b[0;36mScraper._get\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 216\u001b[0m \t\u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request(\u001b[39m'\u001b[39m\u001b[39mGET\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Fikri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\snscrape\\base.py:212\u001b[0m, in \u001b[0;36mScraper._request\u001b[1;34m(self, method, url, params, data, headers, timeout, responseOkCallback, allowRedirects)\u001b[0m\n\u001b[0;32m    210\u001b[0m \tmsg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retries \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m requests to \u001b[39m\u001b[39m{\u001b[39;00mreq\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m failed, giving up.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    211\u001b[0m \tlogger\u001b[39m.\u001b[39mfatal(msg)\n\u001b[1;32m--> 212\u001b[0m \t\u001b[39mraise\u001b[39;00m ScraperException(msg)\n\u001b[0;32m    213\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mReached unreachable code\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mScraperException\u001b[0m: 4 requests to https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&simple_quoted_tweets=true&q=%28from%3ABBC%29+until%3A2023-01-12+since%3A2023-01-08+-filter%3Areplies&tweet_search_mode=live&count=100&query_source=spelling_expansion_revert_click&pc=1&spelling_corrections=1&ext=mediaStats%2ChighlightedLabel failed, giving up."
     ]
    }
   ],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import time\n",
    "\n",
    "query5 = \"(from:BBC) until:2023-01-12 since:2023-01-08 -filter:replies\"\n",
    "\n",
    "news = [query5]\n",
    "tweets = []\n",
    "\n",
    "for news_data in news:\n",
    "    limit = 500\n",
    "    for tweet in sntwitter.TwitterSearchScraper(news_data).get_items():\n",
    "\n",
    "        # print(vars(tweet))\n",
    "        # break\n",
    "        if len(tweets) == limit:\n",
    "            break\n",
    "        else:\n",
    "            tweets.append([tweet.date, tweet.username, tweet.content])\n",
    "        \n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error retrieving https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&simple_quoted_tweets=true&q=from%3Ajack&tweet_search_mode=live&count=100&query_source=spelling_expansion_revert_click&pc=1&spelling_corrections=1&ext=mediaStats%2ChighlightedLabel: non-200 status code\n",
      "4 requests to https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&simple_quoted_tweets=true&q=from%3Ajack&tweet_search_mode=live&count=100&query_source=spelling_expansion_revert_click&pc=1&spelling_corrections=1&ext=mediaStats%2ChighlightedLabel failed, giving up.\n",
      "Exception ignored in: <function tqdm.__del__ at 0x000002474F288700>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Fikri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\std.py\", line 1162, in __del__\n",
      "    self.close()\n",
      "  File \"c:\\Users\\Fikri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\notebook.py\", line 288, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n"
     ]
    },
    {
     "ename": "ScraperException",
     "evalue": "4 requests to https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&simple_quoted_tweets=true&q=from%3Ajack&tweet_search_mode=live&count=100&query_source=spelling_expansion_revert_click&pc=1&spelling_corrections=1&ext=mediaStats%2ChighlightedLabel failed, giving up.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mScraperException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32md:\\CODING TWITTER PROJECT\\0.0 SCRAPING.ipynb Cell 11\u001b[0m in \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CODING%20TWITTER%20PROJECT/0.0%20SCRAPING.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m tweets_list1 \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CODING%20TWITTER%20PROJECT/0.0%20SCRAPING.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Using TwitterSearchScraper to scrape data and append tweets to list\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/CODING%20TWITTER%20PROJECT/0.0%20SCRAPING.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m i,tweet \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(sntwitter\u001b[39m.\u001b[39mTwitterSearchScraper(\u001b[39m'\u001b[39m\u001b[39mfrom:jack\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mget_items()): \u001b[39m#declare a username \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CODING%20TWITTER%20PROJECT/0.0%20SCRAPING.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mif\u001b[39;00m i\u001b[39m>\u001b[39m\u001b[39m1000\u001b[39m: \u001b[39m#number of tweets you want to scrape\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CODING%20TWITTER%20PROJECT/0.0%20SCRAPING.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Fikri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\snscrape\\modules\\twitter.py:680\u001b[0m, in \u001b[0;36mTwitterSearchScraper.get_items\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    677\u001b[0m \t\u001b[39mdel\u001b[39;00m params[\u001b[39m'\u001b[39m\u001b[39mtweet_search_mode\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    678\u001b[0m \t\u001b[39mdel\u001b[39;00m paginationParams[\u001b[39m'\u001b[39m\u001b[39mtweet_search_mode\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m--> 680\u001b[0m \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_api_data(\u001b[39m'\u001b[39m\u001b[39mhttps://api.twitter.com/2/search/adaptive.json\u001b[39m\u001b[39m'\u001b[39m, params, paginationParams, cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cursor):\n\u001b[0;32m    681\u001b[0m \t\u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_instructions_to_tweets(obj)\n",
      "File \u001b[1;32mc:\\Users\\Fikri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\snscrape\\modules\\twitter.py:369\u001b[0m, in \u001b[0;36m_TwitterAPIScraper._iter_api_data\u001b[1;34m(self, endpoint, params, paginationParams, cursor, direction)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    368\u001b[0m \t_logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRetrieving scroll page \u001b[39m\u001b[39m{\u001b[39;00mcursor\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 369\u001b[0m \tobj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_api_data(endpoint, reqParams)\n\u001b[0;32m    370\u001b[0m \t\u001b[39myield\u001b[39;00m obj\n\u001b[0;32m    372\u001b[0m \t\u001b[39m# No data format test, just a hard and loud crash if anything's wrong :-)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Fikri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\snscrape\\modules\\twitter.py:339\u001b[0m, in \u001b[0;36m_TwitterAPIScraper._get_api_data\u001b[1;34m(self, endpoint, params)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_api_data\u001b[39m(\u001b[39mself\u001b[39m, endpoint, params):\n\u001b[0;32m    338\u001b[0m \t\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_guest_token()\n\u001b[1;32m--> 339\u001b[0m \tr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get(endpoint, params \u001b[39m=\u001b[39;49m params, headers \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apiHeaders, responseOkCallback \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_api_response)\n\u001b[0;32m    340\u001b[0m \t\u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    341\u001b[0m \t\tobj \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[1;32mc:\\Users\\Fikri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\snscrape\\base.py:216\u001b[0m, in \u001b[0;36mScraper._get\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 216\u001b[0m \t\u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request(\u001b[39m'\u001b[39m\u001b[39mGET\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Fikri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\snscrape\\base.py:212\u001b[0m, in \u001b[0;36mScraper._request\u001b[1;34m(self, method, url, params, data, headers, timeout, responseOkCallback, allowRedirects)\u001b[0m\n\u001b[0;32m    210\u001b[0m \tmsg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retries \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m requests to \u001b[39m\u001b[39m{\u001b[39;00mreq\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m failed, giving up.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    211\u001b[0m \tlogger\u001b[39m.\u001b[39mfatal(msg)\n\u001b[1;32m--> 212\u001b[0m \t\u001b[39mraise\u001b[39;00m ScraperException(msg)\n\u001b[0;32m    213\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mReached unreachable code\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mScraperException\u001b[0m: 4 requests to https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&simple_quoted_tweets=true&q=from%3Ajack&tweet_search_mode=live&count=100&query_source=spelling_expansion_revert_click&pc=1&spelling_corrections=1&ext=mediaStats%2ChighlightedLabel failed, giving up."
     ]
    }
   ],
   "source": [
    "# importing libraries and packages\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas\n",
    "\n",
    "# Creating list to append tweet data \n",
    "tweets_list1 = []\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:jack').get_items()): #declare a username \n",
    "    if i>1000: #number of tweets you want to scrape\n",
    "        break\n",
    "    tweets_list1.append([tweet.date, tweet.id, tweet.content, tweet.user.username]) #declare the attributes to be returned\n",
    "    \n",
    "# Creating a dataframe from the tweets list above \n",
    "tweets_df1 = pd.DataFrame(tweets_list1, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
