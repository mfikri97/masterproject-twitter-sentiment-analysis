{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.3</th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Username</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date Created</th>\n",
       "      <th>Number of Likes</th>\n",
       "      <th>Number of Retweet</th>\n",
       "      <th>Number of Replies</th>\n",
       "      <th>Source of Tweet</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Conversation ID</th>\n",
       "      <th>status</th>\n",
       "      <th>Category</th>\n",
       "      <th>Translated Text</th>\n",
       "      <th>Translated Cleaned Text</th>\n",
       "      <th>Sentiment Scores</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7860</td>\n",
       "      <td>sarahsslyn</td>\n",
       "      <td>@XavierNaxa @XavierNaxa min kenapa iphone 11 s...</td>\n",
       "      <td>2021-12-30 07:53:41+00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1.476461e+18</td>\n",
       "      <td>1.476403e+18</td>\n",
       "      <td>reply</td>\n",
       "      <td>Technology</td>\n",
       "      <td>@XavierNaxa @XavierNaxa why does my iphone 11 ...</td>\n",
       "      <td>iphone ring talk people person heard talking r...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.859, 'pos': 0.141, 'comp...</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>7889</td>\n",
       "      <td>ewanac</td>\n",
       "      <td>@XavierNaxa ip7+ boleh support smpi ios berapa...</td>\n",
       "      <td>2021-12-31 03:01:55+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1.476750e+18</td>\n",
       "      <td>1.476403e+18</td>\n",
       "      <td>reply</td>\n",
       "      <td>Technology</td>\n",
       "      <td>@XavierNaxa ip7+ can support up to how many ios?</td>\n",
       "      <td>support ios</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.27, 'pos': 0.73, 'compou...</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>7892</td>\n",
       "      <td>maisaradina1</td>\n",
       "      <td>@XavierNaxa Wswwqaaqqaaqaaqaaqqaqaaaqqaqsq</td>\n",
       "      <td>2021-12-31 03:02:30+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>1.476751e+18</td>\n",
       "      <td>1.476403e+18</td>\n",
       "      <td>reply</td>\n",
       "      <td>Technology</td>\n",
       "      <td>@XavierNaxa Wow</td>\n",
       "      <td>wow</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>7893</td>\n",
       "      <td>serilee_</td>\n",
       "      <td>@XavierNaxa @hanisofea19 @bbabygallll haha</td>\n",
       "      <td>2021-12-31 04:55:34+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1.476779e+18</td>\n",
       "      <td>1.476403e+18</td>\n",
       "      <td>reply</td>\n",
       "      <td>Technology</td>\n",
       "      <td>@XavierNaxa @hanisofea19 @bbabygallll haha</td>\n",
       "      <td>haha</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>7894</td>\n",
       "      <td>ahmadalhedra</td>\n",
       "      <td>@XavierNaxa Tahniah anda buat pilihan yg tepat...</td>\n",
       "      <td>2021-12-31 05:18:35+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1.476785e+18</td>\n",
       "      <td>1.476403e+18</td>\n",
       "      <td>reply</td>\n",
       "      <td>Technology</td>\n",
       "      <td>@XavierNaxa Congratulations you made the right...</td>\n",
       "      <td>congratulations choice</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.204, 'pos': 0.796, 'comp...</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57210</th>\n",
       "      <td>115104</td>\n",
       "      <td>115104</td>\n",
       "      <td>115104</td>\n",
       "      <td>9662</td>\n",
       "      <td>SyedSaddiq</td>\n",
       "      <td>Sebab itu saya pertahankan mandat rakyat sampa...</td>\n",
       "      <td>2021-10-30 15:27:18+00:00</td>\n",
       "      <td>187.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1.454470e+18</td>\n",
       "      <td>1.454470e+18</td>\n",
       "      <td>Main post</td>\n",
       "      <td>Politics</td>\n",
       "      <td>That's why I defend the people's mandate until...</td>\n",
       "      <td>defend people mandate today power broker throw...</td>\n",
       "      <td>{'neg': 0.088, 'neu': 0.615, 'pos': 0.296, 'co...</td>\n",
       "      <td>0.6597</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57211</th>\n",
       "      <td>115106</td>\n",
       "      <td>115106</td>\n",
       "      <td>115106</td>\n",
       "      <td>10900</td>\n",
       "      <td>SyedSaddiq</td>\n",
       "      <td>I’m so confused.\\n\\nBoleh ke tak ni buat progr...</td>\n",
       "      <td>2021-10-24 05:03:35+00:00</td>\n",
       "      <td>3347.0</td>\n",
       "      <td>2608.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1.452139e+18</td>\n",
       "      <td>1.452139e+18</td>\n",
       "      <td>Main post</td>\n",
       "      <td>Politics</td>\n",
       "      <td>I'm so confused.\\n\\nIs it possible to hold a l...</td>\n",
       "      <td>confused hold large scale program closed hall ...</td>\n",
       "      <td>{'neg': 0.187, 'neu': 0.813, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57212</th>\n",
       "      <td>115107</td>\n",
       "      <td>115107</td>\n",
       "      <td>115107</td>\n",
       "      <td>11142</td>\n",
       "      <td>SyedSaddiq</td>\n",
       "      <td>Banyak kali saya suarakan.\\n\\nSebab itu,\\n\\n1)...</td>\n",
       "      <td>2021-10-22 10:33:57+00:00</td>\n",
       "      <td>1495.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1.451497e+18</td>\n",
       "      <td>1.451497e+18</td>\n",
       "      <td>Main post</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Many times I voiced it.\\n\\nBecause of that,\\n\\...</td>\n",
       "      <td>times voiced minister salary cut reject discou...</td>\n",
       "      <td>{'neg': 0.251, 'neu': 0.645, 'pos': 0.104, 'co...</td>\n",
       "      <td>-0.6249</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57213</th>\n",
       "      <td>115108</td>\n",
       "      <td>115108</td>\n",
       "      <td>115108</td>\n",
       "      <td>11445</td>\n",
       "      <td>SyedSaddiq</td>\n",
       "      <td>“Tertuduh yang juga penjual ikan didakwa memil...</td>\n",
       "      <td>2021-10-17 15:00:44+00:00</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1.449752e+18</td>\n",
       "      <td>1.449752e+18</td>\n",
       "      <td>Main post</td>\n",
       "      <td>Politics</td>\n",
       "      <td>\"The accused, who is also a fish seller, is ac...</td>\n",
       "      <td>accused fish seller accused possessing drug sy...</td>\n",
       "      <td>{'neg': 0.409, 'neu': 0.395, 'pos': 0.196, 'co...</td>\n",
       "      <td>-0.7941</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57214</th>\n",
       "      <td>115109</td>\n",
       "      <td>115109</td>\n",
       "      <td>115109</td>\n",
       "      <td>13337</td>\n",
       "      <td>SyedSaddiq</td>\n",
       "      <td>Dulu teruk kami dimaki.\\n\\nKini mereka teruska...</td>\n",
       "      <td>2021-10-01 05:06:25+00:00</td>\n",
       "      <td>3627.0</td>\n",
       "      <td>3782.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1.443804e+18</td>\n",
       "      <td>1.443804e+18</td>\n",
       "      <td>Main post</td>\n",
       "      <td>Politics</td>\n",
       "      <td>We used to be scolded badly.\\n\\nNow they conti...</td>\n",
       "      <td>scolded badly continue policy hypocritical mal...</td>\n",
       "      <td>{'neg': 0.22, 'neu': 0.653, 'pos': 0.128, 'com...</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57215 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.3  Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0      Username  \\\n",
       "0                 2             2             2        7860    sarahsslyn   \n",
       "1                29            29            29        7889        ewanac   \n",
       "2                32            32            32        7892  maisaradina1   \n",
       "3                33            33            33        7893      serilee_   \n",
       "4                34            34            34        7894  ahmadalhedra   \n",
       "...             ...           ...           ...         ...           ...   \n",
       "57210        115104        115104        115104        9662    SyedSaddiq   \n",
       "57211        115106        115106        115106       10900    SyedSaddiq   \n",
       "57212        115107        115107        115107       11142    SyedSaddiq   \n",
       "57213        115108        115108        115108       11445    SyedSaddiq   \n",
       "57214        115109        115109        115109       13337    SyedSaddiq   \n",
       "\n",
       "                                                    Text  \\\n",
       "0      @XavierNaxa @XavierNaxa min kenapa iphone 11 s...   \n",
       "1      @XavierNaxa ip7+ boleh support smpi ios berapa...   \n",
       "2             @XavierNaxa Wswwqaaqqaaqaaqaaqqaqaaaqqaqsq   \n",
       "3             @XavierNaxa @hanisofea19 @bbabygallll haha   \n",
       "4      @XavierNaxa Tahniah anda buat pilihan yg tepat...   \n",
       "...                                                  ...   \n",
       "57210  Sebab itu saya pertahankan mandat rakyat sampa...   \n",
       "57211  I’m so confused.\\n\\nBoleh ke tak ni buat progr...   \n",
       "57212  Banyak kali saya suarakan.\\n\\nSebab itu,\\n\\n1)...   \n",
       "57213  “Tertuduh yang juga penjual ikan didakwa memil...   \n",
       "57214  Dulu teruk kami dimaki.\\n\\nKini mereka teruska...   \n",
       "\n",
       "                    Date Created  Number of Likes  Number of Retweet  \\\n",
       "0      2021-12-30 07:53:41+00:00              6.0                0.0   \n",
       "1      2021-12-31 03:01:55+00:00              0.0                1.0   \n",
       "2      2021-12-31 03:02:30+00:00              0.0                0.0   \n",
       "3      2021-12-31 04:55:34+00:00              0.0                0.0   \n",
       "4      2021-12-31 05:18:35+00:00              0.0                0.0   \n",
       "...                          ...              ...                ...   \n",
       "57210  2021-10-30 15:27:18+00:00            187.0               39.0   \n",
       "57211  2021-10-24 05:03:35+00:00           3347.0             2608.0   \n",
       "57212  2021-10-22 10:33:57+00:00           1495.0              482.0   \n",
       "57213  2021-10-17 15:00:44+00:00           1395.0              591.0   \n",
       "57214  2021-10-01 05:06:25+00:00           3627.0             3782.0   \n",
       "\n",
       "       Number of Replies      Source of Tweet       User ID  Conversation ID  \\\n",
       "0                    2.0   Twitter for iPhone  1.476461e+18     1.476403e+18   \n",
       "1                    0.0      Twitter Web App  1.476750e+18     1.476403e+18   \n",
       "2                    0.0  Twitter for Android  1.476751e+18     1.476403e+18   \n",
       "3                    0.0   Twitter for iPhone  1.476779e+18     1.476403e+18   \n",
       "4                    1.0   Twitter for iPhone  1.476785e+18     1.476403e+18   \n",
       "...                  ...                  ...           ...              ...   \n",
       "57210               75.0   Twitter for iPhone  1.454470e+18     1.454470e+18   \n",
       "57211              150.0   Twitter for iPhone  1.452139e+18     1.452139e+18   \n",
       "57212               70.0   Twitter for iPhone  1.451497e+18     1.451497e+18   \n",
       "57213               54.0   Twitter for iPhone  1.449752e+18     1.449752e+18   \n",
       "57214               76.0   Twitter for iPhone  1.443804e+18     1.443804e+18   \n",
       "\n",
       "          status    Category  \\\n",
       "0          reply  Technology   \n",
       "1          reply  Technology   \n",
       "2          reply  Technology   \n",
       "3          reply  Technology   \n",
       "4          reply  Technology   \n",
       "...          ...         ...   \n",
       "57210  Main post    Politics   \n",
       "57211  Main post    Politics   \n",
       "57212  Main post    Politics   \n",
       "57213  Main post    Politics   \n",
       "57214  Main post    Politics   \n",
       "\n",
       "                                         Translated Text  \\\n",
       "0      @XavierNaxa @XavierNaxa why does my iphone 11 ...   \n",
       "1       @XavierNaxa ip7+ can support up to how many ios?   \n",
       "2                                        @XavierNaxa Wow   \n",
       "3             @XavierNaxa @hanisofea19 @bbabygallll haha   \n",
       "4      @XavierNaxa Congratulations you made the right...   \n",
       "...                                                  ...   \n",
       "57210  That's why I defend the people's mandate until...   \n",
       "57211  I'm so confused.\\n\\nIs it possible to hold a l...   \n",
       "57212  Many times I voiced it.\\n\\nBecause of that,\\n\\...   \n",
       "57213  \"The accused, who is also a fish seller, is ac...   \n",
       "57214  We used to be scolded badly.\\n\\nNow they conti...   \n",
       "\n",
       "                                 Translated Cleaned Text  \\\n",
       "0      iphone ring talk people person heard talking r...   \n",
       "1                                            support ios   \n",
       "2                                                    wow   \n",
       "3                                                   haha   \n",
       "4                                 congratulations choice   \n",
       "...                                                  ...   \n",
       "57210  defend people mandate today power broker throw...   \n",
       "57211  confused hold large scale program closed hall ...   \n",
       "57212  times voiced minister salary cut reject discou...   \n",
       "57213  accused fish seller accused possessing drug sy...   \n",
       "57214  scolded badly continue policy hypocritical mal...   \n",
       "\n",
       "                                        Sentiment Scores  Sentiment  \\\n",
       "0      {'neg': 0.0, 'neu': 0.859, 'pos': 0.141, 'comp...     0.2023   \n",
       "1      {'neg': 0.0, 'neu': 0.27, 'pos': 0.73, 'compou...     0.4019   \n",
       "2      {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...     0.5859   \n",
       "3      {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...     0.4588   \n",
       "4      {'neg': 0.0, 'neu': 0.204, 'pos': 0.796, 'comp...     0.5994   \n",
       "...                                                  ...        ...   \n",
       "57210  {'neg': 0.088, 'neu': 0.615, 'pos': 0.296, 'co...     0.6597   \n",
       "57211  {'neg': 0.187, 'neu': 0.813, 'pos': 0.0, 'comp...    -0.3182   \n",
       "57212  {'neg': 0.251, 'neu': 0.645, 'pos': 0.104, 'co...    -0.6249   \n",
       "57213  {'neg': 0.409, 'neu': 0.395, 'pos': 0.196, 'co...    -0.7941   \n",
       "57214  {'neg': 0.22, 'neu': 0.653, 'pos': 0.128, 'com...    -0.4767   \n",
       "\n",
       "      sentiment_label  \n",
       "0            Positive  \n",
       "1            Positive  \n",
       "2            Positive  \n",
       "3            Positive  \n",
       "4            Positive  \n",
       "...               ...  \n",
       "57210        Positive  \n",
       "57211        Negative  \n",
       "57212        Negative  \n",
       "57213        Negative  \n",
       "57214        Negative  \n",
       "\n",
       "[57215 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = pd.read_csv('3 VADERphase.csv')\n",
    "df_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entrepreneur = df_merged[df_merged[\"Category\"] == \"Entrepreneur\"]\n",
    "df_entertainer = df_merged[df_merged[\"Category\"] == \"Entertainer\"]\n",
    "df_technology = df_merged[df_merged[\"Category\"] == \"Technology\"]\n",
    "df_celebrity = df_merged[df_merged[\"Category\"] == \"Celebrity\"]\n",
    "df_politics = df_merged[df_merged[\"Category\"] == \"Politics\"]\n",
    "df_others = df_merged[df_merged[\"Category\"] == \"Fitness and others\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'clf__C': 1, 'clf__gamma': 0.01, 'clf__kernel': 'linear', 'vect__ngram_range': (1, 1)}\n",
      "Best score: 0.9579436183123964\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Replace NaN values with an empty string\n",
    "df_merged['Translated Cleaned Text'] = df_merged['Translated Cleaned Text'].fillna('')\n",
    "\n",
    "# Define the pipeline with CountVectorizer, SVM classifier, and parameter grid for hyperparameter tuning\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', SVC()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'clf__kernel': ('linear', 'rbf'),\n",
    "    'clf__C': [0.1, 1, 10,1000],\n",
    "    'clf__gamma': [0.01,0.02,0.03,0.04,0.05,0.06,0.1, 1],\n",
    "}\n",
    "\n",
    "# Define the GridSearchCV object with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_merge, X_test_merge, y_train_merge, y_test_merge = train_test_split(df_merged['Translated Cleaned Text'], \n",
    "                                                                df_merged['Sentiment'].apply(lambda score: 1 if score > 0 else 0),\n",
    "                                                                test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train_merge, y_train_merge)\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9636458970549681\n",
      "Precision: 0.9705799151343706\n",
      "Recall: 0.9705799151343706\n",
      "F1 score: 0.9705799151343706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Fit a final model on the entire training set using the best hyperparameters\n",
    "pipeline.set_params(**grid_search.best_params_)\n",
    "pipeline.fit(X_train_merge, y_train_merge)\n",
    "\n",
    "# Use the final model to make predictions on the test set\n",
    "y_pred_merge = pipeline.predict(X_test_merge)\n",
    "\n",
    "# Evaluate the performance of the final model on the test set\n",
    "accuracy_merge = accuracy_score(y_test_merge, y_pred_merge)\n",
    "precision_merge = precision_score(y_test_merge, y_pred_merge)\n",
    "recall_merge = recall_score(y_test_merge, y_pred_merge)\n",
    "f1_merge = f1_score(y_test_merge, y_pred_merge)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_merge}\")\n",
    "print(f\"Precision: {precision_merge}\")\n",
    "print(f\"Recall: {recall_merge}\")\n",
    "print(f\"F1 score: {f1_merge}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_merge = pd.DataFrame({'text': X_test_merge, 'vader_label': y_test_merge, 'predicted_label': y_pred_merge})\n",
    "output_merge.to_csv(\"svm_merge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column in the test data portion of df_merged and assign the predicted labels to it\n",
    "df_merged.loc[y_test_merge.index, 'SVM Predicted Label'] = y_pred_merge\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "df_merged.to_csv('updated_df_merged.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fikri\\AppData\\Local\\Temp\\ipykernel_16080\\2761322868.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_technology['Translated Cleaned Text'] = df_technology['Translated Cleaned Text'].fillna('')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'clf__C': 1, 'clf__gamma': 0.01, 'clf__kernel': 'linear', 'vect__ngram_range': (1, 1)}\n",
      "Best score: 0.8403827639525046\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Replace NaN values with an empty string\n",
    "df_technology['Translated Cleaned Text'] = df_technology['Translated Cleaned Text'].fillna('')\n",
    "\n",
    "# Define the pipeline with CountVectorizer, SVM classifier, and parameter grid for hyperparameter tuning\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', SVC()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'clf__kernel': ('linear', 'rbf'),\n",
    "    'clf__C': [0.1, 1, 10,1000],\n",
    "    'clf__gamma': [0.01,0.02,0.03,0.04,0.05,0.06,0.1, 1],\n",
    "}\n",
    "\n",
    "# Define the GridSearchCV object with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_tech, X_test_tech, y_train_tech, y_test_tech = train_test_split(df_technology['Translated Cleaned Text'], \n",
    "                                                                df_technology['Sentiment'].apply(lambda score: 1 if score > 0 else 0),\n",
    "                                                                test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train_tech, y_train_tech)\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8661971830985915\n",
      "Precision: 0.8908629441624365\n",
      "Recall: 0.9140625\n",
      "F1 score: 0.9023136246786632\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Fit a final model on the entire training set using the best hyperparameters\n",
    "pipeline.set_params(**grid_search.best_params_)\n",
    "pipeline.fit(X_train_tech, y_train_tech)\n",
    "\n",
    "# Use the final model to make predictions on the test set\n",
    "y_pred_tech = pipeline.predict(X_test_tech)\n",
    "\n",
    "# Evaluate the performance of the final model on the test set\n",
    "accuracy_tech = accuracy_score(y_test_tech, y_pred_tech)\n",
    "precision_tech = precision_score(y_test_tech, y_pred_tech)\n",
    "recall_tech = recall_score(y_test_tech, y_pred_tech)\n",
    "f1_tech = f1_score(y_test_tech, y_pred_tech)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_tech}\")\n",
    "print(f\"Precision: {precision_tech}\")\n",
    "print(f\"Recall: {recall_tech}\")\n",
    "print(f\"F1 score: {f1_tech}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tech = pd.DataFrame({'text': X_test_tech, 'vader_label': y_test_tech, 'predicted_label': y_pred_tech})\n",
    "output_tech.to_csv(\"svm_tech.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fikri\\AppData\\Local\\Temp\\ipykernel_16080\\2872777365.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_technology.loc[y_test_tech.index, 'SVM Predicted Label'] = y_pred_tech\n"
     ]
    }
   ],
   "source": [
    "# Create a new column in the test data portion of df_merged and assign the predicted labels to it\n",
    "df_technology.loc[y_test_tech.index, 'SVM Predicted Label'] = y_pred_tech\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "df_technology.to_csv('updated_df_tech.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fikri\\AppData\\Local\\Temp\\ipykernel_16080\\1809369241.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_politics['Translated Cleaned Text'] =df_politics['Translated Cleaned Text'].fillna('')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'clf__C': 1, 'clf__gamma': 0.01, 'clf__kernel': 'linear', 'vect__ngram_range': (1, 1)}\n",
      "Best score: 0.9480161590835771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Replace NaN values with an empty string\n",
    "df_politics['Translated Cleaned Text'] =df_politics['Translated Cleaned Text'].fillna('')\n",
    "\n",
    "# Define the pipeline with CountVectorizer, SVM classifier, and parameter grid for hyperparameter tuning\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', SVC()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'clf__kernel': ('linear', 'rbf'),\n",
    "    'clf__C': [0.1, 1, 10,1000],\n",
    "    'clf__gamma': [0.01,0.1, 1, 10,100],\n",
    "}\n",
    "\n",
    "# Define the GridSearchCV object with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_pol, X_test_pol, y_train_pol, y_test_pol = train_test_split(df_politics['Translated Cleaned Text'], \n",
    "                                                                df_politics['Sentiment'].apply(lambda score: 1 if score > 0 else 0),\n",
    "                                                                test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train_pol, y_train_pol)\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9532761957423279\n",
      "Precision: 0.9576291359200191\n",
      "Recall: 0.9617499402342816\n",
      "F1 score: 0.9596851145038168\n"
     ]
    }
   ],
   "source": [
    "# Fit a final model on the entire training set using the best hyperparameters\n",
    "pipeline.set_params(**grid_search.best_params_)\n",
    "pipeline.fit(X_train_pol, y_train_pol)\n",
    "\n",
    "# Use the final model to make predictions on the test set\n",
    "y_pred_pol = pipeline.predict(X_test_pol)\n",
    "\n",
    "# Evaluate the performance of the final model on the test set\n",
    "accuracy_pol = accuracy_score(y_test_pol, y_pred_pol)\n",
    "precision_pol = precision_score(y_test_pol, y_pred_pol)\n",
    "recall_pol = recall_score(y_test_pol, y_pred_pol)\n",
    "f1_pol = f1_score(y_test_pol, y_pred_pol)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_pol}\")\n",
    "print(f\"Precision: {precision_pol}\")\n",
    "print(f\"Recall: {recall_pol}\")\n",
    "print(f\"F1 score: {f1_pol}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pol = pd.DataFrame({'text': X_test_pol, 'vader_label': y_test_pol, 'predicted_label': y_pred_pol})\n",
    "output_pol.to_csv(\"svm_politic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fikri\\AppData\\Local\\Temp\\ipykernel_16080\\496997231.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_politics.loc[y_test_pol.index, 'SVM Predicted Label'] = y_pred_pol\n"
     ]
    }
   ],
   "source": [
    "# Create a new column in the test data portion of df_merged and assign the predicted labels to it\n",
    "df_politics.loc[y_test_pol.index, 'SVM Predicted Label'] = y_pred_pol\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "df_politics.to_csv('updated_df_pol.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fikri\\AppData\\Local\\Temp\\ipykernel_16080\\829794100.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_entrepreneur['Translated Cleaned Text'] =df_entrepreneur['Translated Cleaned Text'].fillna('')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'clf__C': 1, 'clf__gamma': 0.01, 'clf__kernel': 'linear', 'vect__ngram_range': (1, 1)}\n",
      "Best score: 0.9127351221439023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Replace NaN values with an empty string\n",
    "df_entrepreneur['Translated Cleaned Text'] =df_entrepreneur['Translated Cleaned Text'].fillna('')\n",
    "\n",
    "# Define the pipeline with CountVectorizer, SVM classifier, and parameter grid for hyperparameter tuning\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', SVC()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'clf__kernel': ('linear', 'rbf'),\n",
    "    'clf__C': [0.1, 1, 10,1000],\n",
    "    'clf__gamma': [0.01,0.1, 1, 10,100],\n",
    "}\n",
    "\n",
    "# Define the GridSearchCV object with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_entrep, X_test_entrep, y_train_entrep, y_test_entrep = train_test_split(df_entrepreneur['Translated Cleaned Text'], \n",
    "                                                                df_entrepreneur['Sentiment'].apply(lambda score: 1 if score > 0 else 0),\n",
    "                                                                test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train_entrep, y_train_entrep)\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9144838212634823\n",
      "Precision: 0.9291084854994629\n",
      "Recall: 0.9505494505494505\n",
      "F1 score: 0.939706681151548\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Fit a final model on the entire training set using the best hyperparameters\n",
    "pipeline.set_params(**grid_search.best_params_)\n",
    "pipeline.fit(X_train_entrep, y_train_entrep)\n",
    "\n",
    "# Use the final model to make predictions on the test set\n",
    "y_pred_entrep = pipeline.predict(X_test_entrep)\n",
    "\n",
    "# Evaluate the performance of the final model on the test set\n",
    "accuracy_entrep = accuracy_score(y_test_entrep, y_pred_entrep)\n",
    "precision_entrep = precision_score(y_test_entrep, y_pred_entrep)\n",
    "recall_entrep = recall_score(y_test_entrep, y_pred_entrep)\n",
    "f1_entrep = f1_score(y_test_entrep, y_pred_entrep)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_entrep}\")\n",
    "print(f\"Precision: {precision_entrep}\")\n",
    "print(f\"Recall: {recall_entrep}\")\n",
    "print(f\"F1 score: {f1_entrep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_entrep = pd.DataFrame({'text': X_test_entrep, 'vader_label': y_test_entrep, 'predicted_label': y_pred_entrep})\n",
    "output_entrep.to_csv(\"svm_entrep.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fikri\\AppData\\Local\\Temp\\ipykernel_16080\\2966863844.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_entrepreneur.loc[y_test_entrep.index, 'SVM Predicted Label'] = y_pred_entrep\n"
     ]
    }
   ],
   "source": [
    "# Create a new column in the test data portion of df_merged and assign the predicted labels to it\n",
    "df_entrepreneur.loc[y_test_entrep.index, 'SVM Predicted Label'] = y_pred_entrep\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "df_entrepreneur.to_csv('updated_df_entrep.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fikri\\AppData\\Local\\Temp\\ipykernel_16080\\4272066955.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_celebrity['Translated Cleaned Text'] =df_celebrity['Translated Cleaned Text'].fillna('')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'clf__C': 1, 'clf__gamma': 0.01, 'clf__kernel': 'linear', 'vect__ngram_range': (1, 1)}\n",
      "Best score: 0.8730925352597179\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Replace NaN values with an empty string\n",
    "df_celebrity['Translated Cleaned Text'] =df_celebrity['Translated Cleaned Text'].fillna('')\n",
    "\n",
    "# Define the pipeline with CountVectorizer, SVM classifier, and parameter grid for hyperparameter tuning\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', SVC()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'clf__kernel': ('linear', 'rbf'),\n",
    "    'clf__C': [0.1, 1, 10,1000],\n",
    "    'clf__gamma': [0.01,0.1, 1, 10,100],\n",
    "}\n",
    "\n",
    "# Define the GridSearchCV object with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_celeb, X_test_celeb, y_train_celeb, y_test_celeb = train_test_split(df_celebrity['Translated Cleaned Text'], \n",
    "                                                                df_celebrity['Sentiment'].apply(lambda score: 1 if score > 0 else 0),\n",
    "                                                                test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train_celeb, y_train_celeb)\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9154929577464789\n",
      "Precision: 0.9186046511627907\n",
      "Recall: 0.9753086419753086\n",
      "F1 score: 0.9461077844311376\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Fit a final model on the entire training set using the best hyperparameters\n",
    "pipeline.set_params(**grid_search.best_params_)\n",
    "pipeline.fit(X_train_celeb, y_train_celeb)\n",
    "\n",
    "# Use the final model to make predictions on the test set\n",
    "y_pred_celeb = pipeline.predict(X_test_celeb)\n",
    "\n",
    "# Evaluate the performance of the final model on the test set\n",
    "accuracy_celeb = accuracy_score(y_test_celeb, y_pred_celeb)\n",
    "precision_celeb = precision_score(y_test_celeb, y_pred_celeb)\n",
    "recall_celeb = recall_score(y_test_celeb, y_pred_celeb)\n",
    "f1_celeb = f1_score(y_test_celeb, y_pred_celeb)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_celeb}\")\n",
    "print(f\"Precision: {precision_celeb}\")\n",
    "print(f\"Recall: {recall_celeb}\")\n",
    "print(f\"F1 score: {f1_celeb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_celeb = pd.DataFrame({'text': X_test_celeb, 'vader_label': y_test_celeb, 'predicted_label': y_pred_celeb})\n",
    "output_celeb.to_csv(\"svm_celeb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fikri\\AppData\\Local\\Temp\\ipykernel_16080\\3929145901.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_celebrity.loc[y_test_celeb.index, 'SVM Predicted Label'] = y_pred_celeb\n"
     ]
    }
   ],
   "source": [
    "# Create a new column in the test data portion of df_merged and assign the predicted labels to it\n",
    "df_celebrity.loc[y_test_celeb.index, 'SVM Predicted Label'] = y_pred_celeb\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "df_celebrity.to_csv('updated_df_celeb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fikri\\AppData\\Local\\Temp\\ipykernel_16080\\611527851.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_entertainer['Translated Cleaned Text'] =df_entertainer['Translated Cleaned Text'].fillna('')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'clf__C': 1, 'clf__gamma': 0.01, 'clf__kernel': 'linear', 'vect__ngram_range': (1, 2)}\n",
      "Best score: 0.9258765979738011\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Replace NaN values with an empty string\n",
    "df_entertainer['Translated Cleaned Text'] =df_entertainer['Translated Cleaned Text'].fillna('')\n",
    "\n",
    "# Define the pipeline with CountVectorizer, SVM classifier, and parameter grid for hyperparameter tuning\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', SVC()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'clf__kernel': ('linear', 'rbf'),\n",
    "    'clf__C': [0.1, 1, 10,1000],\n",
    "    'clf__gamma': [0.01,0.1, 1, 10,100],\n",
    "}\n",
    "\n",
    "# Define the GridSearchCV object with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_enter, X_test_enter, y_train_enter, y_test_enter = train_test_split(df_entertainer['Translated Cleaned Text'], \n",
    "                                                                df_entertainer['Sentiment'].apply(lambda score: 1 if score > 0 else 0),\n",
    "                                                                test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train_enter, y_train_enter)\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9269430051813472\n",
      "Precision: 0.927892234548336\n",
      "Recall: 0.959049959049959\n",
      "F1 score: 0.9432138542086187\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Fit a final model on the entire training set using the best hyperparameters\n",
    "pipeline.set_params(**grid_search.best_params_)\n",
    "pipeline.fit(X_train_enter, y_train_enter)\n",
    "\n",
    "# Use the final model to make predictions on the test set\n",
    "y_pred_enter = pipeline.predict(X_test_enter)\n",
    "\n",
    "# Evaluate the performance of the final model on the test set\n",
    "accuracy_enter = accuracy_score(y_test_enter, y_pred_enter)\n",
    "precision_enter = precision_score(y_test_enter, y_pred_enter)\n",
    "recall_enter = recall_score(y_test_enter, y_pred_enter)\n",
    "f1_enter = f1_score(y_test_enter, y_pred_enter)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_enter}\")\n",
    "print(f\"Precision: {precision_enter}\")\n",
    "print(f\"Recall: {recall_enter}\")\n",
    "print(f\"F1 score: {f1_enter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_enter = pd.DataFrame({'text': X_test_enter, 'vader_label': y_test_enter, 'predicted_label': y_pred_enter})\n",
    "output_enter.to_csv(\"svm_enter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fikri\\AppData\\Local\\Temp\\ipykernel_16080\\659843509.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_entertainer.loc[y_test_enter.index, 'SVM Predicted Label'] = y_pred_enter\n"
     ]
    }
   ],
   "source": [
    "# Create a new column in the test data portion of df_merged and assign the predicted labels to it\n",
    "df_entertainer.loc[y_test_enter.index, 'SVM Predicted Label'] = y_pred_enter\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "df_entertainer.to_csv('updated_df_enter.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fikri\\AppData\\Local\\Temp\\ipykernel_16080\\573671987.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_others['Translated Cleaned Text'] =df_others['Translated Cleaned Text'].fillna('')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'clf__C': 1000, 'clf__gamma': 0.01, 'clf__kernel': 'rbf', 'vect__ngram_range': (1, 1)}\n",
      "Best score: 0.8185185185185185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Replace NaN values with an empty string\n",
    "df_others['Translated Cleaned Text'] =df_others['Translated Cleaned Text'].fillna('')\n",
    "\n",
    "# Define the pipeline with CountVectorizer, SVM classifier, and parameter grid for hyperparameter tuning\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', SVC()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'clf__kernel': ('linear', 'rbf'),\n",
    "    'clf__C': [0.1, 1, 10,1000],\n",
    "    'clf__gamma': [0.01,0.1, 1, 10,100],\n",
    "}\n",
    "\n",
    "# Define the GridSearchCV object with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_others, X_test_others, y_train_others, y_test_others = train_test_split(df_others['Translated Cleaned Text'], \n",
    "                                                                df_others['Sentiment'].apply(lambda score: 1 if score > 0 else 0),\n",
    "                                                                test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train_others, y_train_others)\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7635467980295566\n",
      "Precision: 0.7737226277372263\n",
      "Recall: 0.8617886178861789\n",
      "F1 score: 0.8153846153846154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Fit a final model on the entire training set using the best hyperparameters\n",
    "pipeline.set_params(**grid_search.best_params_)\n",
    "pipeline.fit(X_train_others, y_train_others)\n",
    "\n",
    "# Use the final model to make predictions on the test set\n",
    "y_pred_others = pipeline.predict(X_test_others)\n",
    "\n",
    "# Evaluate the performance of the final model on the test set\n",
    "accuracy_others = accuracy_score(y_test_others, y_pred_others)\n",
    "precision_others = precision_score(y_test_others, y_pred_others)\n",
    "recall_others = recall_score(y_test_others, y_pred_others)\n",
    "f1_others = f1_score(y_test_others, y_pred_others)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_others}\")\n",
    "print(f\"Precision: {precision_others}\")\n",
    "print(f\"Recall: {recall_others}\")\n",
    "print(f\"F1 score: {f1_others}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_others = pd.DataFrame({'text': X_test_others, 'vader_label': y_test_others, 'predicted_label': y_pred_others})\n",
    "output_others.to_csv(\"svm_others.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fikri\\AppData\\Local\\Temp\\ipykernel_16080\\3208066785.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_others.loc[y_test_others.index, 'SVM Predicted Label'] = y_pred_others\n"
     ]
    }
   ],
   "source": [
    "# Create a new column in the test data portion of df_merged and assign the predicted labels to it\n",
    "df_others.loc[y_test_others.index, 'SVM Predicted Label'] = y_pred_others\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "df_others.to_csv('updated_df_others.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9b8631af70f74c0d798f41702a40d0f748abeb6c6f1a069af3db66893b58922"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
